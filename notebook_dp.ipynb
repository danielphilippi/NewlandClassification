{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions \n",
    "datain_path = 'data/'\n",
    "\n",
    "explorations_path = 'explorations/'\n",
    "if not os.path.exists(explorations_path): \n",
    "    os.makedirs(explorations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('train', 'Train.xlsx'),\n",
    "    ('test', 'Test.xlsx')  \n",
    "]\n",
    "datasets = pd.DataFrame(datasets, columns=['name', 'path']).set_index('name')\n",
    "\n",
    "dataset_name = 'train'\n",
    "dataset_path = datasets.loc[dataset_name].path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_excel(os.path.join(datain_path, dataset_path))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## profile report\n",
    "\n",
    "profile = ProfileReport(\n",
    "    data,\n",
    "    title='Raw data',\n",
    "    minimal=False, \n",
    "    correlations={\n",
    "    \"pearson\": {\"calculate\": True},\n",
    "    \"spearman\": {\"calculate\": False},\n",
    "    \"kendall\": {\"calculate\": False},\n",
    "    \"phi_k\": {\"calculate\": False},\n",
    "    \"cramers\": {\"calculate\": False},\n",
    "    }\n",
    ")\n",
    "profile.to_file(os.path.join(explorations_path, 'profile_data_raw.html'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature=10\n",
    "\n",
    "def get_feature_imp_by_expl(data, base_col, n_feature=n_feature): \n",
    "    \n",
    "    # make sure every combination of levels exist, fill with 0 if no obs\n",
    "    base = data[base_col].unique()\n",
    "    Income = [0, 1]\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [base, Income],\n",
    "        names=[base_col, 'Income']\n",
    "    )\n",
    "\n",
    "    pd1 = pd.DataFrame(index=idx)\n",
    "    \n",
    "\n",
    "    a = data.groupby([base_col, 'Income']).size().to_frame().rename(columns={0:'nobs'})\n",
    "    \n",
    "    a = pd.concat([pd1, a], axis=1)\n",
    "    a.loc[a.nobs.isna(), 'nobs'] = 0\n",
    "    \n",
    "    a['nobs_rel'] = a.groupby(level=base_col).transform(lambda x: x / (x[0] + x[1]))\n",
    "    value_cols = a.columns.to_list()\n",
    "    a.reset_index(inplace=True)\n",
    "    \n",
    "    # top Features by nobs: \n",
    "    topFeat = data.groupby(base_col).size().to_frame().rename(columns={0:'nobs'})\\\n",
    "        .sort_values('nobs', ascending=False).iloc[0:n_feature,:]\\\n",
    "        .index.to_list()\n",
    "    \n",
    "    a.sort_values(['nobs', base_col], ascending=False, inplace=True)\n",
    "    \n",
    "    #print('len(topFeat)', len(topFeat))\n",
    "    #print('len(a)', len(a))\n",
    "    #print('n_feature', n_feature)\n",
    "    #print('a[base_col].nunique()', a[base_col].nunique())\n",
    "\n",
    "    if len(topFeat) < a[base_col].nunique(): \n",
    "        print(f'***Features Filtered to top_{n_feature} by nobs!***')\n",
    "    #print(a[base_col].nunique())\n",
    "\n",
    "    a = a.loc[a[base_col].isin(topFeat),:]\n",
    "    return a, value_cols\n",
    "\n",
    "def plot_feature_imp_by_expl(data, base_col): \n",
    "    \n",
    "    a, value_cols = get_feature_imp_by_expl(data, base_col)\n",
    "    n_plots = len(value_cols) + 1\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = n_plots  , figsize=(20,7), gridspec_kw={'width_ratios': [3,3,1]})\n",
    "    for i, col in enumerate(value_cols): \n",
    "        sns.barplot(data=a, x=base_col, y=col, hue='Income', ax=ax[i])#.set_title(col) # [0:10]\n",
    "        ax[i].tick_params(labelrotation=45)\n",
    "\n",
    "    sns.countplot(data=data, x='Income', ax=ax[n_plots-1])\n",
    "    plt.show()\n",
    "    \n",
    "def get_target_ratio(data):  \n",
    "    a = data.groupby(['Income']).size().to_frame().rename(columns={0:'nobs'})\n",
    "    a['nobs_rel'] = a.transform(lambda x: x / (x[0] + x[1]))\n",
    "    value_cols = a.columns.to_list()\n",
    "    a.reset_index(inplace=True)\n",
    "    return a.loc[a.Income == 1, 'nobs_rel'].to_list()[0]\n",
    "\n",
    "\n",
    "def get_feature_imp_by_target_ratio(data, base_col, weighted=False): \n",
    "\n",
    "    target_ratio = get_target_ratio(data)\n",
    "    target_ratio\n",
    "                                            \n",
    "    a, _ = get_feature_imp_by_expl(data, base_col, n_feature=100)\n",
    "    \n",
    "    #########\n",
    "    nObsPerFeatClass =  data.groupby([base_col]).size().to_frame().rename(columns={0:'nobs'})\n",
    "                           \n",
    "\n",
    "    ratio_per_level = a.loc[a.Income == 1, [base_col,'nobs_rel']]\\\n",
    "        .set_index(base_col)\\\n",
    "        .rename(columns={'nobs_rel':'class1_ratio'})\n",
    "\n",
    "    ratio_per_level = pd.concat([ratio_per_level, nObsPerFeatClass], axis=1)\n",
    "    #min_max_scaler_obs = MinMaxScaler()\n",
    "    ratio_per_level['nobs_rel'] = ratio_per_level.nobs / sum(ratio_per_level.nobs)\n",
    "\n",
    "\n",
    "    \n",
    "    ratio_per_level['diff_to_target'] = ratio_per_level['class1_ratio'] - target_ratio\n",
    "    ratio_per_level['diff_to_target_dir'] = ['neg' if obs < 0 else 'pos' for obs in ratio_per_level['diff_to_target']]\n",
    "    \n",
    "    if weighted: \n",
    "        weights = np.power(ratio_per_level['nobs_rel'], 1./3)\n",
    "    else: \n",
    "        weights = 1\n",
    "        \n",
    "    ratio_per_level['diff_to_target_abs'] = abs(ratio_per_level['diff_to_target']) * weights\n",
    "    \n",
    "    #print(ratio_per_level)\n",
    "\n",
    "    ratio_per_level.sort_values('diff_to_target_abs', ascending=False, inplace=True)\n",
    "    ratio_per_level['diff_to_target_abs_cumsum'] = ratio_per_level.diff_to_target_abs.cumsum()\n",
    "    ratio_per_level\n",
    "\n",
    "\n",
    "    x = ratio_per_level['diff_to_target_abs_cumsum'].values.reshape(-1, 1) #df.values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    ratio_per_level['diff_to_target_abs_cumsum_scaled'] = min_max_scaler.fit_transform(x)\n",
    "\n",
    "    print('TargetClass1_ratio', target_ratio)\n",
    "    print(ratio_per_level[['diff_to_target_dir', 'diff_to_target_abs']])\n",
    "\n",
    "    return ratio_per_level\n",
    "\n",
    "\n",
    "def plot_feature_imp_by_target_ratio(data, base_col, weighted=False): \n",
    "\n",
    "    r = get_feature_imp_by_target_ratio(data, base_col, weighted)\n",
    "\n",
    "    sns.lineplot(data=r, y=r.index, x='diff_to_target_abs_cumsum_scaled')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_feature_imp_by_tree(data, base_col, n_feature=n_feature): \n",
    "    # prepare\n",
    "    onehot = OneHotEncoder()\n",
    "    X_train_cat = data.loc[:,[base_col]]\n",
    "    #X_train_cat = data[base_col]\n",
    "\n",
    "    X_train_onehot = onehot.fit_transform(X_train_cat)\n",
    "    X_train_onehot_df = pd.DataFrame(X_train_onehot.toarray(), columns=onehot.get_feature_names())\n",
    "    X_train_onehot_df\n",
    "\n",
    "    X_train_onehot_df = pd.get_dummies(data[base_col], prefix=base_col)\n",
    "\n",
    "    # train\n",
    "    dt_gini = DecisionTreeClassifier(random_state = 1)\n",
    "    X_train = X_train_onehot_df#.drop(columns=['x0_Africa','x0_Europe', 'x0_Oceania'])\n",
    "    y_train = data.Income\n",
    "\n",
    "\n",
    "    dt_gini.fit(X_train, y_train) # data[base_col]\n",
    "    print('Score:', dt_gini.score(X_train, y_train))\n",
    "\n",
    "    #dt_gini.feature_importances_\n",
    "    #tree.plot_tree(dt_gini)\n",
    "\n",
    "    #plt.barh(onehot.get_feature_names(), dt_gini.feature_importances_)\n",
    "\n",
    "    #print(dt_gini.feature_importances_)\n",
    "    sorted_idx = dt_gini.feature_importances_.argsort()#[0:10]\n",
    "    plotdata = pd.DataFrame({\n",
    "        'Feature': X_train.columns[sorted_idx], \n",
    "        'Importance': dt_gini.feature_importances_[sorted_idx]}).sort_values('Importance', ascending=False)\n",
    "    #plt.barh()\n",
    "    #print(plotdata)\n",
    "    sns.barplot(data=plotdata.iloc[0:n_feature,:], x='Importance', y='Feature')\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_feature_imp(data, base_col, force_barplot=True, weighted=False): \n",
    "    print('Class distributions')\n",
    "    if (data[base_col].nunique() < 6) | force_barplot:\n",
    "        n_plots = 2\n",
    "        plot_feature_imp_by_expl(data, base_col)\n",
    "    else: \n",
    "        n_plots = 1\n",
    "        \n",
    "    print('\\nElbow')        \n",
    "    plot_feature_imp_by_target_ratio(data, base_col, weighted)\n",
    "    \n",
    "    print('\\nDecision Tree')\n",
    "    plot_feature_imp_by_tree(data, base_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_col = 'Marital Status'\n",
    "plot_feature_imp(data, base_col, weighted=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_col = 'Marital Status'\n",
    "plot_feature_imp(data, base_col, weighted=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init \n",
    "cols_to_drop = []\n",
    "cols_to_onehot = []\n",
    "\n",
    "# prep\n",
    "pred_config = {\n",
    "    'cardinality': 'low' # low, medium, high, original\n",
    "} \n",
    "\n",
    "cardinality = pred_config['cardinality']\n",
    "print('cardinality:', cardinality)\n",
    "\n",
    "error_log = {'cleaning': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract gender from name?!\n",
    "salutation = data.Name.str.split(' ', n=1, expand=True)[0]\n",
    "if salutation.nunique() != 3: \n",
    "    raise ValueError('Unexpected levels of salutation')\n",
    "    \n",
    "print(salutation.value_counts())\n",
    "\n",
    "#gender = ['male' if s == 'Mr.' else 'female' for s in salutation]\n",
    "#data['gender'] = gender\n",
    "\n",
    "male = [1 if s == 'Mr.' else 0 if s in ['Mrs.', 'Miss'] else np.nan for s in salutation]\n",
    "data['male'] = male\n",
    "\n",
    "if data.male.isna().sum() > 0: \n",
    "    raise Warning('NAs instroduced')\n",
    "    \n",
    "cols_to_drop.append('Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat variable cleaning framework\n",
    "base_col = ''\n",
    "target_col = ''\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'low':\n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "    elif cardinality == 'medium': \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "    elif cardinality == 'high': \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "    elif cardinality == 'original':\n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "    \n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(data=data, x='male')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(data=data, hue=data.Income, x='male')#.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute age from Birthday\n",
    "\n",
    "# clean whitespaces\n",
    "data.Birthday = data.Birthday.str.replace(' ', '')\n",
    "# define date format\n",
    "dob_format = '%B%d,%Y'\n",
    "\n",
    "# transform Birthday to datetime, catching the leap year error \n",
    "\n",
    "## helper fct to subtract one day from datetime if error occurs\n",
    "def subone(obj):\n",
    "    val = int(obj.group(0))\n",
    "    return str(val-1)\n",
    "\n",
    "## init and loop over dates\n",
    "dob = []\n",
    "error_log = []\n",
    "for i, d in enumerate(data.Birthday): \n",
    "    try: \n",
    "        dob.append(datetime.strptime(d, dob_format).date())\n",
    "\n",
    "    except ValueError as e: \n",
    "        if str(e) == 'day is out of range for month': \n",
    "            dt = datetime.strptime(re.sub('\\d{1,2}', subone, d, count=1), dob_format).date()\n",
    "            error_log.append((d, dt))\n",
    "            dob.append(dt)\n",
    "        else: \n",
    "            raise NotImplementedError('Do not know how to deal with that error!')\n",
    "            dt = np.nan\n",
    "            error_log.append((d, dt))\n",
    "            dob.append(dt)\n",
    "        \n",
    "# add age column \n",
    "data['age'] = [np.floor((datetime.strptime('2048-12-31', '%Y-%m-%d').date() - d).days / 365.2425) for d in dob]\n",
    "\n",
    "# inspect\n",
    "sns.histplot(data, x='age')\n",
    "plt.show()\n",
    "print('Min age:' , min(data.age))\n",
    "\n",
    "# drop date col \n",
    "cols_to_drop.append('Birthday')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Native Continent' to bin \n",
    "base_col = 'Native Continent'\n",
    "target_col = 'from_europe_or_asia'\n",
    "#sns.countplot(data=data, hue=data.Income, x=base_col)#.set_title(col)\n",
    "#plt.show()\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "#data['from_europe'] = [1 if a == 'Europe' else 0 for a in data[base_col]]\n",
    "data[target_col] = [1 if a in ['Europe', 'Asia'] else 0 for a in data[base_col]]\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marital Status\n",
    "base_col = 'Marital Status'\n",
    "#target_col = 'marital_status'\n",
    "\n",
    "data[base_col].value_counts()\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "if (cardinality == 'low'): \n",
    "    target_col = 'maritalStatus_married'\n",
    "    data[target_col] = [1 if a in ['Married', 'Married - Spouse in the Army'] else 0 for a in data[base_col]]\n",
    "else: \n",
    "    target_col = 'maritalStatus'\n",
    "    mapping = {\n",
    "        'Married':'Married',\n",
    "        'Single':'Single',\n",
    "        'Divorced':'Divorced',\n",
    "        'Separated':'Separated',\n",
    "        'Widow':'Widow',\n",
    "        'Married - Spouse Missing':'SpouseMissing',\n",
    "        'Married - Spouse in the Army':'Married'\n",
    "    }\n",
    "\n",
    "    data[target_col] = data[base_col].map(mapping)\n",
    "    cols_to_onehot.append(target_col)\n",
    "\n",
    "#sns.countplot(data=data, x=target_col)\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lives with\n",
    "\n",
    "\n",
    "base_col = 'Lives with'\n",
    "print(data[base_col].value_counts())\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "if(cardinality == 'low'): \n",
    "    target_col = 'household_livesWithPartner'\n",
    "    data[target_col] = [1 if a in ['Wife', 'Husband'] else 0 for a in data[base_col]]\n",
    "else: \n",
    "    target_col = 'household'\n",
    "    mapping = {\n",
    "        'Wife': 'Partner',\n",
    "        'Other Family': 'Family',\n",
    "        'Children': 'Children',\n",
    "        'Alone': 'Alone',\n",
    "        'Husband': 'Partner',\n",
    "        'Other relatives': 'Family'\n",
    "    }\n",
    "\n",
    "    print(mapping)\n",
    "\n",
    "    data[target_col] = data[base_col].map(mapping)\n",
    "    cols_to_onehot.append(target_col)\n",
    "\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'Base Area' to bin \n",
    "base_col = 'Base Area'\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "try: \n",
    "    if cardinality == 'low': \n",
    "        target_col = 'basearea_fanfoss' # basearea_northbury\n",
    "        target_val = 'Fanfoss'\n",
    "        target_col_alt = 'basearea_northbury'\n",
    "        target_val_alt = 'Northbury'\n",
    "\n",
    "        print('\\nResult:')\n",
    "        data[target_col] = [1 if a == target_val else 0 for a in data[base_col]]\n",
    "        sns.countplot(data=data, x=target_col, hue='Income')\n",
    "        plt.show()\n",
    "\n",
    "        print('\\nAlternative result:')\n",
    "        test = data[['Income', base_col]].copy()\n",
    "        test[target_col_alt] = [1 if a == target_val_alt else 0 for a in test[base_col]]\n",
    "        sns.countplot(data=test, x=target_col_alt, hue='Income')\n",
    "        plt.show()\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "\n",
    "cols_to_drop.append(base_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Education Level \n",
    "base_col = 'Education Level'\n",
    "target_col = 'education'\n",
    "print(data.columns)\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "\n",
    "edu_mapping = pd.read_excel(os.path.join(datain_path, 'edu_mapping_2.xlsx'), 'Tabelle2')\n",
    "mapping_options = ['level_0', 'level_1', 'numeric', 'original', 'low']\n",
    "\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'low':\n",
    "        m_option = mapping_options[4]\n",
    "        plot_fct = sns.countplot\n",
    "    elif cardinality == 'medium': \n",
    "        m_option = mapping_options[1]\n",
    "        plot_fct = sns.countplot\n",
    "    elif cardinality == 'high': \n",
    "        m_option = mapping_options[2]\n",
    "        plot_fct = sns.histplot\n",
    "    elif cardinality == 'original':\n",
    "        m_option = mapping_options[3]\n",
    "        plot_fct = sns.countplot       \n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "\n",
    "\n",
    "#print(data[base_col].value_counts())\n",
    "\n",
    "#mapping = dict(edu_mapping[['name', mapping_options[2]]].set_index('name'))\n",
    "#mapping = {k:v for k,v in edu_mapping[['name', mapping_options[2]]].set_index('name').items()}\n",
    "#mapping = edu_mapping[['name', mapping_options[2]]].set_index('name')\n",
    "mapping = edu_mapping[['name', m_option]].rename(columns={m_option: target_col})\n",
    "print(mapping)\n",
    "\n",
    "# drop if reruning the cell \n",
    "if target_col in data.columns: \n",
    "    data.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "data = data.merge(mapping, left_on=base_col, right_on='name', how='left')\n",
    "data.drop(columns=['name'], inplace=True)  \n",
    "\n",
    "# plot target col against prediction classes\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plot_fct(data=data, x=target_col, hue='Income', ax=ax)\n",
    "#plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)\n",
    "\n",
    "\n",
    "data[[base_col, target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years of education \n",
    "base_col = 'Years of Education'\n",
    "target_col = 'education_years'\n",
    "data.rename(columns={base_col: target_col}, inplace=True)\n",
    "\n",
    "data.head()\n",
    "#sns.histplot(data=data, y=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Employment Sector\n",
    "base_col = 'Employment Sector'\n",
    "target_col = 'empl_sector'\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'deprecated':\n",
    "        mapping = {\n",
    "            'Private Sector - Services ': 'private',\n",
    "            'Self-Employed (Individual)': 'self',\n",
    "            'Public Sector - Others': 'public',\n",
    "            '?': 'unknown',\n",
    "            'Private Sector - Others': 'private',\n",
    "            'Self-Employed (Company)': 'self',\n",
    "            'Public Sector - Government': 'public',\n",
    "            'Unemployed': 'delete',\n",
    "            'Never Worked': 'delete'\n",
    "            }\n",
    "\n",
    "    elif cardinality in ['low', 'original']: \n",
    "        mapping = {\n",
    "            'Private Sector - Services ': 'private_services',\n",
    "            'Self-Employed (Individual)': 'self_individual',\n",
    "            'Public Sector - Others': 'public_others',\n",
    "            '?': 'unknown',\n",
    "            'Private Sector - Others': 'private_others',\n",
    "            'Self-Employed (Company)': 'self_company',\n",
    "            'Public Sector - Government': 'public_gov',\n",
    "            'Unemployed': 'unemployed',\n",
    "            'Never Worked': 'unemployed'\n",
    "            }\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "print(mapping)\n",
    "    \n",
    "data[target_col] = data[base_col].map(mapping)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "sns.countplot(data=data, x=target_col, hue='Income', ax=ax)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# role\n",
    "base_col = 'Role'\n",
    "target_col = 'empl_role'\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'low':\n",
    "        mapping = {\n",
    "            'Professor': 'Professor',\n",
    "            'Management': 'Management',\n",
    "            'Repair & constructions': 'Operational_low',\n",
    "            'Administratives': 'Operational',\n",
    "            'Sales': 'Sales',\n",
    "            'Other services': 'Services',\n",
    "            'Machine Operators & Inspectors': 'Operational',\n",
    "            '?': 'unknown',\n",
    "            'Transports': 'Operational_low',\n",
    "            'Cleaners & Handlers': 'Cleaners',\n",
    "            'Agriculture and Fishing': 'Operational',\n",
    "            'IT': 'Rest',\n",
    "            'Security': 'Rest',\n",
    "            'Household Services': 'blue_collor',\n",
    "            'Army': 'Operational_low'\n",
    "        }\n",
    "    elif cardinality == 'original':       \n",
    "        mapping = {\n",
    "            'Professor': 'Professor',\n",
    "            'Management': 'Management',\n",
    "            'Repair & constructions': 'Constructions',\n",
    "            'Administratives': 'Administratives',\n",
    "            'Sales': 'Sales',\n",
    "            'Other services': 'Services',\n",
    "            'Machine Operators & Inspectors': 'Operator',\n",
    "            '?': 'unknown',\n",
    "            'Transports': 'Transports',\n",
    "            'Cleaners & Handlers': 'Cleaners',\n",
    "            'Agriculture and Fishing': 'Agriculture',\n",
    "            'IT': 'IT', \n",
    "            'Security': 'Security',\n",
    "            'Household Services': 'Household',\n",
    "            'Army': 'Army'\n",
    "        }\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "print(mapping)\n",
    "    \n",
    "data[target_col] = data[base_col].map(mapping)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "sns.countplot(data=data, x=target_col, hue='Income', ax=ax)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Hours per week\n",
    "base_col = 'Working Hours per week'\n",
    "target_col = 'working_hrs_week'\n",
    "\n",
    "data.rename(columns={base_col: target_col}, inplace=True)\n",
    "\n",
    "sns.histplot(data=data, x=target_col, hue='Income', bins=30)\n",
    "plt.show()\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Money Received\n",
    "base_col = 'Money Received'\n",
    "target_col = 'group_b_received_money'\n",
    "\n",
    "data[target_col] = [1 if v != 0 else 0 for v in data[base_col]]\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "data[[base_col, target_col]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket Price\n",
    "base_col = 'Ticket Price'\n",
    "target_col = 'group_c_payed'\n",
    "\n",
    "data[target_col] = [1 if v != 0 else 0 for v in data[base_col]]\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "data[[base_col, target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols \n",
    "data.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors\n",
    "for name, log in error_log.items():\n",
    "    if len(log) > 0: \n",
    "        print(f'{name}:\\n {log}')\n",
    "        raise Warning('Errors occured! See above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## profile report\n",
    "\n",
    "profile = ProfileReport(\n",
    "    data,\n",
    "    title=f'Cleaned data {dataset_name}' ,\n",
    "    minimal=False, \n",
    "    correlations={\n",
    "    \"pearson\": {\"calculate\": True},\n",
    "    \"spearman\": {\"calculate\": False},\n",
    "    \"kendall\": {\"calculate\": False},\n",
    "    \"phi_k\": {\"calculate\": False},\n",
    "    \"cramers\": {\"calculate\": False},\n",
    "    }\n",
    ")\n",
    "profile.to_file(os.path.join(explorations_path, f'profile_data_cleaned_{dataset_name}.html'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target distribution\n",
    "\n",
    "sns.countplot(data=data, x='Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Obtain correlation matrix. Round the values to 2 decimal cases. Use the DataFrame corr() and round() method.\n",
    "corr = np.round(data.corr(method=\"pearson\"), decimals=2)\n",
    "\n",
    "# Build annotation matrix (values above |0.5| will appear annotated in the plot)\n",
    "mask_annot = np.absolute(corr.values) >= 0.5\n",
    "annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) # Try to understand what this np.where() does\n",
    "\n",
    "# Plot heatmap of the correlation matrix\n",
    "sns.heatmap(data=corr, annot=annot, cmap=sns.diverging_palette(220, 10, as_cmap=True), \n",
    "            fmt='s', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
    "\n",
    "# Layout\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle(\"Correlation Matrix\", fontsize=20)\n",
    "\n",
    "plt.savefig(os.path.join(explorations_path, 'correlation_matrix.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions \n",
    "\n",
    "ncols = 4\n",
    "n_plots = data.shape[1]\n",
    "nrows = int(np.ceil(n_plots/ncols))\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15,13))\n",
    "col_no = 0\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols): \n",
    "        if col_no < n_plots:\n",
    "            col = data.columns[col_no]\n",
    "            print(col)\n",
    "            if data[col].dtype in [np.float, np.int]: \n",
    "                sns.histplot(data=data, hue=data.Income, x=col, ax=ax[i,j], bins=30).set_title(col)\n",
    "            else : \n",
    "                sns.countplot(data=data, hue=data.Income, x=col, ax=ax[i,j], dodge=True).set_title(col)\n",
    "            ax[i,j].tick_params(labelrotation=45)\n",
    "            col_no +=1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(explorations_path, 'distributions.png'), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering ideas\n",
    "- age + household: age diff to mean of hh group\n",
    "- \n",
    "\n",
    "### Imputations: \n",
    "- empl_sector == unkown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# one hot encode \n",
    "#pd.get_dummies(data=data, columns=cols_to_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep config\n",
    "\n",
    "prep_config = {\n",
    "    'upscaling': False, \n",
    "    'normalize': False\n",
    "    'outlier': False # uni- / multivariate, working hours per week\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upcaling to cope with class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
