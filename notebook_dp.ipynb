{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions \n",
    "datain_path = 'data/'\n",
    "\n",
    "explorations_path = 'explorations/'\n",
    "if not os.path.exists(explorations_path): \n",
    "    os.makedirs(explorations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('train', 'Train.xlsx'),\n",
    "    ('test', 'Test.xlsx')  \n",
    "]\n",
    "datasets = pd.DataFrame(datasets, columns=['name', 'path']).set_index('name')\n",
    "\n",
    "dataset_name = 'train'\n",
    "dataset_path = datasets.loc[dataset_name].path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_excel(os.path.join(datain_path, dataset_path))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## profile report\n",
    "\n",
    "profile = ProfileReport(\n",
    "    data,\n",
    "    title='Raw data',\n",
    "    minimal=False, \n",
    "    correlations={\n",
    "    \"pearson\": {\"calculate\": True},\n",
    "    \"spearman\": {\"calculate\": False},\n",
    "    \"kendall\": {\"calculate\": False},\n",
    "    \"phi_k\": {\"calculate\": False},\n",
    "    \"cramers\": {\"calculate\": False},\n",
    "    }\n",
    ")\n",
    "profile.to_file(os.path.join(explorations_path, 'profile_data_raw.html'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp_by_expl(data, base_col): \n",
    "    \n",
    "    # make sure every combination of levels exist, fill with 0 if no obs\n",
    "    base = data[base_col].unique()\n",
    "    Income = [0, 1]\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [base, Income],\n",
    "        names=[base_col, 'Income']\n",
    "    )\n",
    "\n",
    "    pd1 = pd.DataFrame(index=idx)\n",
    "    \n",
    "\n",
    "    a = data.groupby([base_col, 'Income']).size().to_frame().rename(columns={0:'nobs'})\n",
    "    \n",
    "    a = pd.concat([pd1, a], axis=1)\n",
    "    a.loc[a.nobs.isna(), 'nobs'] = 0\n",
    "    \n",
    "    a['nobs_rel'] = a.groupby(level=base_col).transform(lambda x: x / (x[0] + x[1]))\n",
    "    value_cols = a.columns.to_list()\n",
    "    a.reset_index(inplace=True)\n",
    "\n",
    "    a.sort_values(['nobs', base_col], ascending=False, inplace=True)\n",
    "    return a, value_cols\n",
    "\n",
    "def plot_feature_imp_by_expl(data, base_col): \n",
    "    \n",
    "    a, value_cols = get_feature_imp_by_expl(data, base_col)\n",
    "    n_plots = len(value_cols) + 1\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = n_plots  , figsize=(20,7), gridspec_kw={'width_ratios': [3,3,1]})\n",
    "    for i, col in enumerate(value_cols): \n",
    "        sns.barplot(data=a, x=base_col, y=col, hue='Income', ax=ax[i])#.set_title(col) # [0:10]\n",
    "        ax[i].tick_params(labelrotation=45)\n",
    "\n",
    "    sns.countplot(data=data, x='Income', ax=ax[n_plots-1])\n",
    "    plt.show()\n",
    "    \n",
    "def get_target_ratio(data):  \n",
    "    a = data.groupby(['Income']).size().to_frame().rename(columns={0:'nobs'})\n",
    "    a['nobs_rel'] = a.transform(lambda x: x / (x[0] + x[1]))\n",
    "    value_cols = a.columns.to_list()\n",
    "    a.reset_index(inplace=True)\n",
    "    return a.loc[a.Income == 1, 'nobs_rel'].to_list()[0]\n",
    "\n",
    "\n",
    "def get_feature_imp_by_target_ratio(data, base_col, weighted=False): \n",
    "\n",
    "    target_ratio = get_target_ratio(data)\n",
    "    target_ratio\n",
    "                                            \n",
    "    a, _ = get_feature_imp_by_expl(data, base_col)\n",
    "    \n",
    "    #########\n",
    "    nObsPerFeatClass =  data.groupby([base_col]).size().to_frame().rename(columns={0:'nobs'})\n",
    "                           \n",
    "\n",
    "    ratio_per_level = a.loc[a.Income == 1, [base_col,'nobs_rel']]\\\n",
    "        .set_index(base_col)\\\n",
    "        .rename(columns={'nobs_rel':'class1_ratio'})\n",
    "\n",
    "    ratio_per_level = pd.concat([ratio_per_level, nObsPerFeatClass], axis=1)\n",
    "    #min_max_scaler_obs = MinMaxScaler()\n",
    "    ratio_per_level['nobs_rel'] = ratio_per_level.nobs / sum(ratio_per_level.nobs)\n",
    "\n",
    "\n",
    "    \n",
    "    ratio_per_level['diff_to_target'] = ratio_per_level['class1_ratio'] - target_ratio\n",
    "    ratio_per_level['diff_to_target_dir'] = ['neg' if obs < 0 else 'pos' for obs in ratio_per_level['diff_to_target']]\n",
    "    \n",
    "    if weighted: \n",
    "        weights = np.power(ratio_per_level['nobs_rel'], 1./3)\n",
    "    else: \n",
    "        weights = 1\n",
    "        \n",
    "    ratio_per_level['diff_to_target_abs'] = abs(ratio_per_level['diff_to_target']) * weights\n",
    "    \n",
    "    #print(ratio_per_level)\n",
    "\n",
    "    ratio_per_level.sort_values('diff_to_target_abs', ascending=False, inplace=True)\n",
    "    ratio_per_level['diff_to_target_abs_cumsum'] = ratio_per_level.diff_to_target_abs.cumsum()\n",
    "    ratio_per_level\n",
    "\n",
    "\n",
    "    x = ratio_per_level['diff_to_target_abs_cumsum'].values.reshape(-1, 1) #df.values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    ratio_per_level['diff_to_target_abs_cumsum_scaled'] = min_max_scaler.fit_transform(x)\n",
    "\n",
    "    print('TargetClass1_ratio', target_ratio)\n",
    "    print(ratio_per_level[['diff_to_target_dir', 'diff_to_target_abs']])\n",
    "\n",
    "    return ratio_per_level\n",
    "\n",
    "\n",
    "def plot_feature_imp_by_target_ratio(data, base_col, weighted=False): \n",
    "\n",
    "    r = get_feature_imp_by_target_ratio(data, base_col, weighted)\n",
    "\n",
    "    sns.lineplot(data=r, y=r.index, x='diff_to_target_abs_cumsum_scaled')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_feature_imp_by_tree(data, base_col): \n",
    "    # prepare\n",
    "    onehot = OneHotEncoder()\n",
    "    X_train_cat = data.loc[:,[base_col]]\n",
    "    #X_train_cat = data[base_col]\n",
    "\n",
    "    X_train_onehot = onehot.fit_transform(X_train_cat)\n",
    "    X_train_onehot_df = pd.DataFrame(X_train_onehot.toarray(), columns=onehot.get_feature_names())\n",
    "    X_train_onehot_df\n",
    "\n",
    "    X_train_onehot_df = pd.get_dummies(data[base_col], prefix=base_col)\n",
    "\n",
    "    # train\n",
    "    dt_gini = DecisionTreeClassifier(random_state = 1)\n",
    "    X_train = X_train_onehot_df#.drop(columns=['x0_Africa','x0_Europe', 'x0_Oceania'])\n",
    "    y_train = data.Income\n",
    "\n",
    "\n",
    "    dt_gini.fit(X_train, y_train) # data[base_col]\n",
    "    print('Score:', dt_gini.score(X_train, y_train))\n",
    "\n",
    "    #dt_gini.feature_importances_\n",
    "    #tree.plot_tree(dt_gini)\n",
    "\n",
    "    #plt.barh(onehot.get_feature_names(), dt_gini.feature_importances_)\n",
    "\n",
    "    #print(dt_gini.feature_importances_)\n",
    "    sorted_idx = dt_gini.feature_importances_.argsort()#[0:10]\n",
    "    plt.barh(X_train.columns[sorted_idx], dt_gini.feature_importances_[sorted_idx])\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_feature_imp(data, base_col, force_barplot=True, weighted=False): \n",
    "    plot_feature_imp_by_expl(data, base_col)\n",
    "    \n",
    "    \n",
    "    if (data[base_col].nunique() < 6) | force_barplot:\n",
    "        n_plots = 2\n",
    "        plot_feature_imp_by_target_ratio(data, base_col, weighted)\n",
    "    else: \n",
    "        n_plots = 1\n",
    "        \n",
    "    plot_feature_imp_by_tree(data, base_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_imp_by_expl(data, base_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'s': list(range(5))})[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init \n",
    "cols_to_drop = []\n",
    "cols_to_onehot = []\n",
    "\n",
    "# prep\n",
    "pred_config = {\n",
    "    'cardinality': 'low' # low, medium, high\n",
    "} \n",
    "\n",
    "cardinality = pred_config['cardinality']\n",
    "cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract gender from name?!\n",
    "salutation = data.Name.str.split(' ', n=1, expand=True)[0]\n",
    "if salutation.nunique() != 3: \n",
    "    raise ValueError('Unexpected levels of salutation')\n",
    "    \n",
    "print(salutation.value_counts())\n",
    "\n",
    "#gender = ['male' if s == 'Mr.' else 'female' for s in salutation]\n",
    "#data['gender'] = gender\n",
    "\n",
    "male = [1 if s == 'Mr.' else 0 if s in ['Mrs.', 'Miss'] else np.nan for s in salutation]\n",
    "data['male'] = male\n",
    "\n",
    "if data.male.isna().sum() > 0: \n",
    "    raise Warning('NAs instroduced')\n",
    "    \n",
    "cols_to_drop.append('Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(data=data, x='male')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(data=data, hue=data.Income, x='male')#.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute age from Birthday\n",
    "\n",
    "# clean whitespaces\n",
    "data.Birthday = data.Birthday.str.replace(' ', '')\n",
    "# define date format\n",
    "dob_format = '%B%d,%Y'\n",
    "\n",
    "# transform Birthday to datetime, catching the leap year error \n",
    "\n",
    "## helper fct to subtract one day from datetime if error occurs\n",
    "def subone(obj):\n",
    "    val = int(obj.group(0))\n",
    "    return str(val-1)\n",
    "\n",
    "## init and loop over dates\n",
    "dob = []\n",
    "error_log = []\n",
    "for i, d in enumerate(data.Birthday): \n",
    "    try: \n",
    "        dob.append(datetime.strptime(d, dob_format).date())\n",
    "\n",
    "    except ValueError as e: \n",
    "        if str(e) == 'day is out of range for month': \n",
    "            dt = datetime.strptime(re.sub('\\d{1,2}', subone, d, count=1), dob_format).date()\n",
    "            error_log.append((d, dt))\n",
    "            dob.append(dt)\n",
    "        else: \n",
    "            raise NotImplementedError('Do not know how to deal with that error!')\n",
    "            dt = np.nan\n",
    "            error_log.append((d, dt))\n",
    "            dob.append(dt)\n",
    "        \n",
    "# add age column \n",
    "data['age'] = [np.floor((datetime.strptime('2048-12-31', '%Y-%m-%d').date() - d).days / 365.2425) for d in dob]\n",
    "\n",
    "# inspect\n",
    "sns.histplot(data, x='age')\n",
    "plt.show()\n",
    "print('Min age:' , min(data.age))\n",
    "\n",
    "# drop date col \n",
    "cols_to_drop.append('Birthday')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Native Continent' to bin \n",
    "base_col = 'Native Continent'\n",
    "target_col = 'from_europe_or_asia'\n",
    "#sns.countplot(data=data, hue=data.Income, x=base_col)#.set_title(col)\n",
    "#plt.show()\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "#data['from_europe'] = [1 if a == 'Europe' else 0 for a in data[base_col]]\n",
    "data[target_col] = [1 if a in ['Europe', 'Asia'] else 0 for a in data[base_col]]\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marital Status\n",
    "base_col = 'Marital Status'\n",
    "#target_col = 'marital_status'\n",
    "\n",
    "data[base_col].value_counts()\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "if (cardinality == 'low'): \n",
    "    target_col = 'maritalStatus_married'\n",
    "    data[target_col] = [1 if a in ['Married', 'Married - Spouse in the Army'] else 0 for a in data[base_col]]\n",
    "else: \n",
    "    target_col = 'maritalStatus'\n",
    "    mapping = {\n",
    "        'Married':'Married',\n",
    "        'Single':'Single',\n",
    "        'Divorced':'Divorced',\n",
    "        'Separated':'Separated',\n",
    "        'Widow':'Widow',\n",
    "        'Married - Spouse Missing':'SpouseMissing',\n",
    "        'Married - Spouse in the Army':'Married'\n",
    "    }\n",
    "\n",
    "    data[target_col] = data[base_col].map(mapping)\n",
    "    cols_to_onehot.append(target_col)\n",
    "\n",
    "#sns.countplot(data=data, x=target_col)\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lives with\n",
    "\n",
    "\n",
    "base_col = 'Lives with'\n",
    "print(data[base_col].value_counts())\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "if(cardinality == 'low'): \n",
    "    target_col = 'household_livesWithPartner'\n",
    "    data[target_col] = [1 if a in ['Wife', 'Husband'] else 0 for a in data[base_col]]\n",
    "else: \n",
    "    target_col = 'household'\n",
    "    mapping = {\n",
    "        'Wife': 'Partner',\n",
    "        'Other Family': 'Family',\n",
    "        'Children': 'Children',\n",
    "        'Alone': 'Alone',\n",
    "        'Husband': 'Partner',\n",
    "        'Other relatives': 'Family'\n",
    "    }\n",
    "\n",
    "    print(mapping)\n",
    "\n",
    "    data[target_col] = data[base_col].map(mapping)\n",
    "    cols_to_onehot.append(target_col)\n",
    "\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'Base Area' to bin \n",
    "base_col = 'Base Area'\n",
    "\n",
    "plot_feature_imp(data, base_col, weighted=False)\n",
    "\n",
    "\n",
    "data['basearea_northbury'] = [1 if a == 'Northbury' else 0 for a in data[base_col]]\n",
    "sns.countplot(data=data, x='basearea_northbury', hue='Income')\n",
    "plt.show()\n",
    "\n",
    "test = data[['Income', base_col]].copy()\n",
    "test['basearea_fanfoss'] = [1 if a == 'Fanfoss' else 0 for a in test[base_col]]\n",
    "sns.countplot(data=test, x='basearea_fanfoss', hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education Level \n",
    "base_col = 'Education Level'\n",
    "target_col = 'education'\n",
    "\n",
    "#print(data[base_col].value_counts())\n",
    "\n",
    "edu_mapping = pd.read_excel(os.path.join(datain_path, 'edu_mapping_2.xlsx'), 'Tabelle2')\n",
    "mapping_options = ['level_0', 'level_1', 'numeric']\n",
    "m_option = mapping_options[0]\n",
    "\n",
    "#mapping = dict(edu_mapping[['name', mapping_options[2]]].set_index('name'))\n",
    "#mapping = {k:v for k,v in edu_mapping[['name', mapping_options[2]]].set_index('name').items()}\n",
    "#mapping = edu_mapping[['name', mapping_options[2]]].set_index('name')\n",
    "mapping = edu_mapping[['name', m_option]].rename(columns={m_option: target_col})\n",
    "\n",
    "print(mapping)\n",
    "\n",
    "data = data.merge(mapping, left_on=base_col, right_on='name', how='left')\n",
    "data.drop(columns=['name'], inplace=True)  \n",
    "\n",
    "\n",
    "\n",
    "sns.histplot(data=data, x=target_col)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "#cols_to_onehot.append(target_col)\n",
    "\n",
    "\n",
    "data[[base_col, target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years of education \n",
    "base_col = 'Years of Education'\n",
    "target_col = 'education_years'\n",
    "data.rename(columns={base_col: target_col}, inplace=True)\n",
    "\n",
    "data.head()\n",
    "#sns.histplot(data=data, y=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment Sector\n",
    "base_col = 'Employment Sector'\n",
    "target_col = 'empl_sector'\n",
    "\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "mapping = {\n",
    "    'Private Sector - Services ': 'private',\n",
    "    'Self-Employed (Individual)': 'self',\n",
    "    'Public Sector - Others': 'public',\n",
    "    '?': 'unknown',\n",
    "    'Private Sector - Others': 'private',\n",
    "    'Self-Employed (Company)': 'self',\n",
    "    'Public Sector - Government': 'public',\n",
    "    'Unemployed': 'delete',\n",
    "    'Never Worked': 'delete'\n",
    "    }\n",
    "\n",
    "print(mapping)\n",
    "    \n",
    "data[target_col] = data[base_col].map(mapping)\n",
    "\n",
    "sns.countplot(data=data, x=target_col)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role\n",
    "base_col = 'Role'\n",
    "target_col = 'empl_role'\n",
    "\n",
    "mapping = {\n",
    "    'Professor': 'Professor',\n",
    "    'Management': 'Management',\n",
    "    'Repair & constructions': 'blue_collor',\n",
    "    'Administratives': 'Administratives',\n",
    "    'Sales': 'Administratives',\n",
    "    'Other services': 'Services',\n",
    "    'Machine Operators & Inspectors': 'blue_collor',\n",
    "    '?': 'unknown',\n",
    "    'Transports': 'blue_collor',\n",
    "    'Cleaners & Handlers': 'blue_collor',\n",
    "    'Agriculture and Fishing': 'blue_collor',\n",
    "    'IT': 'Administratives',\n",
    "    'Security': 'blue_collor',\n",
    "    'Household Services': 'blue_collor',\n",
    "    'Army': 'blue_collor'\n",
    "}\n",
    "\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "print(mapping)\n",
    "    \n",
    "data[target_col] = data[base_col].map(mapping)\n",
    "\n",
    "sns.countplot(data=data, x=target_col)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Hours per week\n",
    "base_col = 'Working Hours per week'\n",
    "target_col = 'working_hrs_week'\n",
    "\n",
    "data.rename(columns={base_col: target_col}, inplace=True)\n",
    "\n",
    "sns.histplot(data=data, x=target_col)\n",
    "plt.show()\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Money Received\n",
    "base_col = 'Money Received'\n",
    "target_col = 'group_b_received_money'\n",
    "\n",
    "data[target_col] = [1 if v != 0 else 0 for v in data[base_col]]\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n",
    "\n",
    "sns.countplot(data=data, x=target_col)\n",
    "plt.show()\n",
    "\n",
    "data[[base_col, target_col]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket Price\n",
    "base_col = 'Ticket Price'\n",
    "target_col = 'group_c_payed'\n",
    "\n",
    "data[target_col] = [1 if v != 0 else 0 for v in data[base_col]]\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n",
    "\n",
    "sns.countplot(data=data, x=target_col)\n",
    "plt.show()\n",
    "\n",
    "data[[base_col, target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols \n",
    "data.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## profile report\n",
    "\n",
    "profile = ProfileReport(\n",
    "    data,\n",
    "    title=f'Cleaned data {dataset_name}' ,\n",
    "    minimal=False, \n",
    "    correlations={\n",
    "    \"pearson\": {\"calculate\": True},\n",
    "    \"spearman\": {\"calculate\": False},\n",
    "    \"kendall\": {\"calculate\": False},\n",
    "    \"phi_k\": {\"calculate\": False},\n",
    "    \"cramers\": {\"calculate\": False},\n",
    "    }\n",
    ")\n",
    "profile.to_file(os.path.join(explorations_path, f'profile_data_cleaned_{dataset_name}.html'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target distribution\n",
    "\n",
    "sns.countplot(data=data, x='Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Obtain correlation matrix. Round the values to 2 decimal cases. Use the DataFrame corr() and round() method.\n",
    "corr = np.round(data.corr(method=\"pearson\"), decimals=2)\n",
    "\n",
    "# Build annotation matrix (values above |0.5| will appear annotated in the plot)\n",
    "mask_annot = np.absolute(corr.values) >= 0.5\n",
    "annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) # Try to understand what this np.where() does\n",
    "\n",
    "# Plot heatmap of the correlation matrix\n",
    "sns.heatmap(data=corr, annot=annot, cmap=sns.diverging_palette(220, 10, as_cmap=True), \n",
    "            fmt='s', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
    "\n",
    "# Layout\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle(\"Correlation Matrix\", fontsize=20)\n",
    "\n",
    "plt.savefig(os.path.join(explorations_path, 'correlation_matrix.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions \n",
    "\n",
    "ncols = 4\n",
    "n_plots = data.shape[1]\n",
    "nrows = int(np.ceil(n_plots/ncols))\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15,13))\n",
    "col_no = 0\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols): \n",
    "        if col_no < n_plots:\n",
    "            col = data.columns[col_no]\n",
    "            print(col)\n",
    "            g = sns.histplot(data=data, hue=data.Income, x=col, ax=ax[i,j], bins=30).set_title(col)\n",
    "            ax[i,j].tick_params(labelrotation=45)\n",
    "            col_no +=1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(explorations_path, 'distributions.png'), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering ideas\n",
    "- age + household: age diff to mean of hh group\n",
    "- \n",
    "\n",
    "### Imputations: \n",
    "- empl_sector == unkown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# one hot encode \n",
    "#pd.get_dummies(data=data, columns=cols_to_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep config\n",
    "\n",
    "prep_config = {\n",
    "    'upscaling': False, \n",
    "    'normalize': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upcaling to cope with class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
